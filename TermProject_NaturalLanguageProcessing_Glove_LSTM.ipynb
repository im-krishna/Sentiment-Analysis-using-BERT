{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bSUBEBbjxNT"
      },
      "source": [
        "Importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKG3QCVIgE3b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train_data = np.array(pd.read_csv('train.csv'))\n",
        "test_data = np.array(pd.read_csv('test.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bDhK2sdgixL"
      },
      "source": [
        "Preprocessing data\n",
        "- tokenisation\n",
        "- removing un-needed word\n",
        "- lowering, removing punctutaion\n",
        "- removing stop words\n",
        "- stemming (converting word to root word)\n",
        "- taking out the unique list of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIIQqqvuh0mP",
        "outputId": "d2f848ea-b999-460f-adff-b255753dd11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Already Glove embedded vectors"
      ],
      "metadata": {
        "id": "rGsZHynAmaVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CulyrfPHmZ6X",
        "outputId": "6dc2c5c3-7e19-4791-fb6d-1a8918d0fd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-07 16:57:27--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.20MB/s    in 2m 51s  \n",
            "\n",
            "2022-12-07 17:00:19 (4.80 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R7-plyZq_EE",
        "outputId": "cdcf6120-b141-4af6-e688-7fd62d7d87a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "words = dict()\n",
        "\n",
        "def add_to_dict(d, filename):\n",
        "  with open(filename, 'r') as f:\n",
        "    for line in f.readlines():\n",
        "      line = line.split(' ')\n",
        "\n",
        "      try:\n",
        "        d[line[0]] = np.array(line[1:], dtype=float)\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "add_to_dict(words, 'glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "jI06iwt2r5-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing data"
      ],
      "metadata": {
        "id": "eBsQOPcnsEUI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xa1HHvhFgiGq"
      },
      "outputs": [],
      "source": [
        "#removes punctuation from our tokenised dataset\n",
        "def tokenize(sentence):\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  return tokenizer.tokenize(sentence)\n",
        "\n",
        "# .lowering and .stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "def stemmingText(tokenizedSen):\n",
        "  stemmedSen = []\n",
        "  for word in tokenizedSen:\n",
        "    stemmedSen.append(ps.stem(word.lower()))\n",
        "  return stemmedSen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDeJqnImgnNK"
      },
      "outputs": [],
      "source": [
        "def preprocessingData(temp_data):\n",
        "  # we need a training corpus\n",
        "  all_word = []\n",
        "  all_sentences = []\n",
        "  tags = []\n",
        "\n",
        "  for sen,tag,x,y in temp_data:\n",
        "      temp = tokenize(sen) #our tokenised sentence\n",
        "      if 'URL' in temp: #removing unnecessary words\n",
        "          temp.remove('URL')\n",
        "      without_stop_words = []\n",
        "      for word  in temp:\n",
        "          if word not in stopwords.words('english'):\n",
        "              without_stop_words.append(word)\n",
        "      temp = without_stop_words\n",
        "      temp2 = stemmingText(temp) #after stemming\n",
        "      all_word.extend(temp2)#final words are stemmed\n",
        "      tags.append(tag)\n",
        "      all_sentences.append(temp2)\n",
        "          \n",
        "  all_word = sorted(set(all_word))\n",
        "  return (all_word,all_sentences,tags)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre_processed_training_data = preprocessingData(train_data)"
      ],
      "metadata": {
        "id": "mnNbLz5vMXhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_word , all_sentences , tags = pre_processed_training_data "
      ],
      "metadata": {
        "id": "bqCXUsyYIzoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting our preprocessed sentences to vectors of length max length"
      ],
      "metadata": {
        "id": "1JNGtS9VunvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_lengths = []\n",
        "\n",
        "for i in range(len(all_sentences)):\n",
        "  sequence_lengths.append(len(all_sentences[i]))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(sequence_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "SDJ61p0wtRGh",
        "outputId": "285e2e8c-d715-4cc5-f807-2439dac371d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 533., 1562., 1677., 1474.,  942., 1117.,  539.,  132.,   20.,\n",
              "           4.]),\n",
              " array([ 1. ,  4.8,  8.6, 12.4, 16.2, 20. , 23.8, 27.6, 31.4, 35.2, 39. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(sequence_lengths).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y1WmdgMtwIP",
        "outputId": "e7bb94d0-062e-42d1-be84-910ad2e28564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    8000.000000\n",
              "mean       13.727250\n",
              "std         6.695555\n",
              "min         1.000000\n",
              "25%         8.000000\n",
              "50%        13.000000\n",
              "75%        19.000000\n",
              "max        39.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll take length of each sentence to be maximum which is 40 words and if the sentences is less than 40 words we'll pad </br> now input neurons for the neural network would be 50*50 = 2500 where another 50 is dimension of each vector"
      ],
      "metadata": {
        "id": "g7dsy7Int1xG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting our all_sentences to vectors"
      ],
      "metadata": {
        "id": "Yxb8C0Ebu8uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_sen_to_vec(all_sentences):\n",
        "  final_data = []\n",
        "  i=0\n",
        "  for sen in all_sentences:\n",
        "    _sen_to_vector = []\n",
        "    for word in sen:\n",
        "      if word in words:\n",
        "        _sen_to_vector.append(words[word])\n",
        "    _sen_to_vector = np.array(_sen_to_vector,dtype= float)\n",
        "    #basically we have certain sentences in which any word is not present in our words list\n",
        "    #so their inital dimanesion is zero and this will create problem\n",
        "    if _sen_to_vector.shape[0] == 0:\n",
        "     _sen_to_vector = np.zeros(shape=(1, 50))\n",
        "\n",
        "    final_data.append(_sen_to_vector)\n",
        "  return final_data\n"
      ],
      "metadata": {
        "id": "NETYFFtovBBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_training_data = convert_sen_to_vec(all_sentences)"
      ],
      "metadata": {
        "id": "Ni86TYc-xylV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_training_data[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "569SXTd5x-kU",
        "outputId": "24a338f0-01e0-49ec-f790-479bc8b38cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fo padding"
      ],
      "metadata": {
        "id": "3bSIDLkWue0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "def pad_X(X, desired_sequence_length=40):\n",
        "  X_copy = deepcopy(X)\n",
        "  for i, x in enumerate(X):\n",
        "    x_seq_len = x.shape[0]\n",
        "    sequence_length_difference = desired_sequence_length - x_seq_len\n",
        "    pad = np.zeros(shape=(sequence_length_difference, 50))\n",
        "    X_copy[i] = np.concatenate([x, pad])\n",
        "  return np.array(X_copy).astype(float)"
      ],
      "metadata": {
        "id": "BezLUN8XuW2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_training_data = pad_X(final_training_data)"
      ],
      "metadata": {
        "id": "-mZoYIkgyTr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_training_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHS9B-qWi-Va",
        "outputId": "290be2b9-22a6-444e-d05c-f44593ae3b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.19461  , -0.051277 ,  0.26445  , ..., -0.67103  , -0.21652  ,\n",
              "        -0.025891 ],\n",
              "       [-0.075276 , -0.39411  , -0.16369  , ..., -0.86126  , -0.99047  ,\n",
              "         0.92322  ],\n",
              "       [-0.1166   , -0.010887 ,  0.044444 , ...,  0.44057  ,  0.0064518,\n",
              "         1.2454   ],\n",
              "       ...,\n",
              "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
              "         0.       ],\n",
              "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
              "         0.       ],\n",
              "       [ 0.       ,  0.       ,  0.       , ...,  0.       ,  0.       ,\n",
              "         0.       ]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxxGSXSsnpBM"
      },
      "source": [
        "Binary Classification of sexist and not sexist</br>\n",
        "0 - not sexist</br>\n",
        "1 - sexist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pdqdZR8nt_q"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "final_training_tag = le.fit_transform(tags)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_training_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFSv-zY5CcPf",
        "outputId": "584f956d-0bc2-40d0-eccd-92908479ec07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset and Dataloader class "
      ],
      "metadata": {
        "id": "6575SpXnl-ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import math"
      ],
      "metadata": {
        "id": "80B3g2GCL8Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOJVth8tDk1L"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(Dataset):\n",
        "  def __init__(self,final_data,final_tag):\n",
        "    self.x = torch.from_numpy(np.array(final_data))\n",
        "    self.y = torch.from_numpy(np.array(final_tag))\n",
        "    self.n_samples = len(self.x)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return (self.x[index] , self.y[index])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_dataset = SentimentDataset(final_training_data,final_training_tag)\n",
        "train_dataloader = DataLoader(dataset=train_dataset , batch_size = batch_size, shuffle =True, num_workers=2)"
      ],
      "metadata": {
        "id": "o2pLFsqomFDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_dataloader)\n",
        "data = dataiter.next()\n",
        "features,labels = data"
      ],
      "metadata": {
        "id": "iQ-ShzuyOhqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FeedForward"
      ],
      "metadata": {
        "id": "K9mtBEf4q9J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YJFIfPcSsTz",
        "outputId": "fd183d51-f4bb-4c4c-fa24-40c73a5672f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available for running: \n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper - parameters\n",
        "sequence_length = 40\n",
        "input_size= 50\n",
        "#here input_size if the the size of features of one element in the sequence\n",
        "hidden_size = 200\n",
        "num_classes = 1\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "total_samples = len(train_dataset)\n",
        "num_layers = 2"
      ],
      "metadata": {
        "id": "mc7pFlk0q86K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "Z50qO1zuqX73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input to rnn should be in the shape of (batch_size, sequence_length, input_size)\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_layers,num_classes):\n",
        "    super(RNN,self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.rnn=nn.GRU(input_size,hidden_size,num_layers,batch_first = True,nonlinearity = 'relu')\n",
        "    self.linear = nn.Linear(hidden_size,num_classes)\n",
        "    self.sigmoid = torch.sigmoid\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.float()\n",
        "    #we need the the inital hidden state as input in the correct shape\n",
        "    # x.size(0) is the batch size\n",
        "    h0 = torch.zeros(self.num_layers , x.size(0) , self.hidden_size) \n",
        "    out,_ = self.rnn(x,h0)\n",
        "    # shape of o/p batch_size, seq_length, hidden_size\n",
        "    # 32 40 100 \n",
        "    out = out[:, -1 , :] #the tanh function is built inside RNN so we don't need it\n",
        "    #we only need the output after all the sequence has been processed through RNN and we have output\n",
        "    out = out.squeeze() \n",
        "    out = self.linear(out)\n",
        "    out = out.squeeze()\n",
        "    out = self.sigmoid(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "JzXgY6LTsI3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(input_size,hidden_size,num_layers,num_classes)"
      ],
      "metadata": {
        "id": "hE7MSZiwtNwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "17385eb6-4384-4a79-bdb3-15ec30d797c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-03e1fcee2d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-121-4289900cc5a6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, hidden_size, num_layers, num_classes)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnonlinearity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'proj_size'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"proj_size argument is only supported for LSTM, not RNN or GRU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GRU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m  \u001b[0;31m# type: ignore[override]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'nonlinearity'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "#finally CrossEntropy loss applies the softmax function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Dm6vxwHmtSk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "CQb3R2mzt5R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "    #forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs,labels.float())\n",
        "    if (i+1)/250 >= 1:\n",
        "      outputs = (outputs>0.5).float()\n",
        "      correct = (outputs == labels.float()).float().sum()\n",
        "      print(f'epoch {epoch+1}/{num_epochs} loss = {loss.item():.4f} accuracy = {(correct/outputs.shape[0])*100} %')\n",
        "      \n",
        "    #backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() #back propgation\n",
        "    optimizer.step() #update weights for us"
      ],
      "metadata": {
        "id": "RNFf9K6jtyVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf30136-a6e3-4482-bb1a-b9ab4e75efe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/10 loss = 0.5957 accuracy = 71.875 %\n",
            "epoch 2/10 loss = 0.6824 accuracy = 62.5 %\n",
            "epoch 3/10 loss = 0.4546 accuracy = 87.5 %\n",
            "epoch 4/10 loss = 0.4663 accuracy = 84.375 %\n",
            "epoch 5/10 loss = 0.5990 accuracy = 71.875 %\n",
            "epoch 6/10 loss = 0.5958 accuracy = 71.875 %\n",
            "epoch 7/10 loss = 0.5963 accuracy = 71.875 %\n",
            "epoch 8/10 loss = 0.5253 accuracy = 78.125 %\n",
            "epoch 9/10 loss = 0.4956 accuracy = 81.25 %\n",
            "epoch 10/10 loss = 0.5956 accuracy = 71.875 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "awAVItzgdiOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "T,test_all_sentences,test_tags = preprocessingData(test_data)"
      ],
      "metadata": {
        "id": "iNKueWxxkssg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_testing_data = convert_sen_to_vec(test_all_sentences)\n",
        "final_testing_data = pad_X(final_testing_data)\n",
        "final_testing_tags = np.array(le.transform(test_tags))"
      ],
      "metadata": {
        "id": "qllYBhP66Ocq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_testing_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwKoSC15FkJf",
        "outputId": "8b0b5de2-8dea-49bb-eaa3-00dbd1e1e7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 40, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SentimentDataset(final_testing_data,final_testing_tags)\n",
        "test_dataloader = DataLoader(dataset=test_dataset , batch_size = batch_size, shuffle =True, num_workers=2)"
      ],
      "metadata": {
        "id": "b-aRf3Sslqki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_dataloader)\n",
        "data = dataiter.next()\n",
        "features,labels = data\n",
        "print(features.shape,labels.shape)"
      ],
      "metadata": {
        "id": "fxnlRl_hGHiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c786eb-ad92-4304-cfc3-ba85d8fdeee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 40, 50]) torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "for (inputs ,labels) in test_dataloader:\n",
        "  predictions = model(inputs.float())\n",
        "  predictions = (predictions>0.5).float()\n",
        "  correct += (predictions == labels.float()).float().sum()\n",
        "print(f'testing accuracy {(correct/len(test_dataset))*100}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYEQpPxxHTuc",
        "outputId": "4ce159eb-4f9e-4436-f830-1a767ae6a63f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing accuracy 75.9000015258789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxHM9ShHJR70"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}